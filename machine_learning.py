# -*- coding: utf-8 -*-
"""Machine Learning.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1OktaXuMHYKd5NFq2n8cGgR3SB6wVc3Sr
"""

import pandas as pd

# Load dataset
data = pd.read_csv('Conversational_data.csv')

# Display the first few rows of the dataset
print(data.head())

import pandas as pd
import torch
from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments
from sklearn.model_selection import train_test_split
from transformers import pipeline

# Load dataset
data = pd.read_csv('Conversational_data.csv')

# Display the first few rows of the dataset
print(data.head(10))

# Load pre-trained BERT tokenizer and model for sequence classification
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=3)


# Tokenize the input text
inputs = tokenizer(
    data['user_input'].tolist(),
    padding=True,
    truncation=True,
    return_tensors="pt"
)

# Convert intents to numerical labels
labels = torch.tensor([0 if intent == "book_flight" else 1 if intent == "get_weather" else 2 for intent in data['intent']])

# Create a custom dataset class
class CustomDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.labels)

# Create dataset objects
dataset = CustomDataset(inputs, labels)

# Split the dataset into train and test sets
train_dataset, test_dataset = torch.utils.data.random_split(dataset, [int(0.8*len(dataset)), len(dataset) - int(0.8*len(dataset))])

# Define Trainer arguments
training_args = TrainingArguments(
    output_dir='./results',
    num_train_epochs=3,
    per_device_train_batch_size=16,
    per_device_eval_batch_size=64,
    warmup_steps=500,
    weight_decay=0.01,
    logging_dir='./logs',
)

# Initialize the trainer
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=test_dataset,
)

# Fine-tune the model
trainer.train()

# Load pre-trained NER model
ner_model = pipeline("ner", grouped_entities=True)  # Model with grouped entities

feedback_data = []


def predict_intent(user_input):
    # Tokenize the user input
    tokens = tokenizer(user_input, padding=True, truncation=True, return_tensors="pt")


    tokens = {k: v.to(model.device) for k, v in tokens.items()}

    # Predict intent using the model
    with torch.no_grad():
        outputs = model(**tokens)
        predictions = torch.argmax(outputs.logits, dim=-1).item()

    # Map predicted label to intent
    intent_mapping = {0: "book_flight", 1: "get_weather", 2: "other_intent"}
    predicted_intent = intent_mapping[predictions]
    return predicted_intent

# Function to simulate chatbot interaction
def chatbot_response(user_input):
    # Predict intent using the trained model
    predicted_intent = predict_intent(user_input)

    # Print the predicted intent
    print(f"Predicted Intent: {predicted_intent}")

    # Generate dynamic response based on the predicted intent
    if predicted_intent == "book_flight":
        response = "It looks like you want to book a flight. Let me assist you with that."
    elif predicted_intent == "get_weather":
        response = "You are asking about the weather. Let me provide the latest forecast."
    else:
        response = "I'm not sure what you're asking. Could you please clarify?"

    # Print the dynamic response
    print(f"Response: {response}")

    # Extract entities
    entities = ner_model(user_input)

    # Display extracted entities
    print("Entities found:")
    for entity in entities:
        print({
            'word': entity['word'],
            'score': entity['score'],
            'start': entity['start'],
            'end': entity['end'],
            'entity': entity['entity_group']  # Accessing 'entity_group' for entity type
        })

    # Store feedback
    feedback_data.append({
        'user_input': user_input,
        'Entities': entities,
        'Intent': predicted_intent
    })

    # Ask for feedback
    feedback = int(input("Rate the response (1-5): "))
    feedback_data.append({'user_input': user_input, 'response': response, 'feedback': feedback})

    # Store feedback
    pd.DataFrame(feedback_data).to_csv('feedback_data.csv', index=False)

# Simulate a conversation
user_input = input("User: ")
chatbot_response(user_input)

